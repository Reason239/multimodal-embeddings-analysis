# multimodal-embeddings-analysis
Studying the properties of CLIP and RuDolph multimodal embeddings distributions

## Part 1: Embeddings distribution: isotropy, whitening, transforms

![img](https://lh5.googleusercontent.com/BD_MKVSzcJ0XF_37uDXXnuNJbEXwEBUZ8bXTmDXp_PggHovUUjr5OFRLJv4J1Kadznr9EBC306jldswj20PErB3_vIV2Xqwx1kW3S25fXEYWMGLaF3Am8ZT5iDHsrAtSAv_jyzpalzFB_2L1L6nFMw)

**Main notebooks:**

* Full analysis of CLIP Visual transformer model: [Colab](https://colab.research.google.com/drive/1FaV7omnSVLDwGnEJ1U3SRxvhoRUavSVz?usp=sharing) [GitHub](https://github.com/Reason239/multimodal-embeddings-analysis/blob/main/analyze_clip_embeddings_CLIP_ViT_B_32.ipynb)
* Full analysis of CLIP ResNet101 model: [Colab](https://colab.research.google.com/drive/1XU0OlfHE00VNmMA1PlscPVhKsR3iDfNH?usp=sharing) [GitHub](https://github.com/Reason239/multimodal-embeddings-analysis/blob/main/analyze_clip_embeddings_CLIP_RN101.ipynb)
* Image embeddings analysis of RuDolph model: [Colab](https://colab.research.google.com/drive/14zMXDt1JkYRC4hS4iXi9SsrBxJ-X7MY4?usp=sharing) [GitHub](https://github.com/Reason239/multimodal-embeddings-analysis/blob/main/analyze_RuDolph_embeddings.ipynb)
* Precomputing the embeddings: [CLIP Colab](https://colab.research.google.com/drive/1mwLbwlxB03D_IAObr6JTHrXJNh9qrfYo?usp=sharing) [RuDolph Colab](https://colab.research.google.com/drive/1JtbAH5LR52ZYK8BYzwVJaCvngV0PtZj0?authuser=1#scrollTo=t8PlUC-dJXz5)

## Part 2: Multilinguality: metrics and visualization

![img](https://lh3.googleusercontent.com/f_MoPIc9AZKCoaQPqPJxw7j9-po0VwvN8hvVRsrfSRAUXZTYbAISNehh-645cvpne-1MrY_V9pQ-W4jTn4iIQlw0ZCxAjQM1YPVI1VvX8t1aBsRAyy5lHwVlyUDJgB_r8nl2DjvgzX0Ru9nO2U2bsQ)

**Main notebook:**

* Visualization and distance measuring: [GitHub](https://github.com/Reason239/multimodal-embeddings-analysis/blob/main/multilingual_embeddings/multilingual_clip.ipynb)

## Part 3: Style transfer and vector algebra:

Coming soon!
